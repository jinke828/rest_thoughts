{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9556308-9ede-4618-9fba-1253c1adfa2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module https://tfhub.dev/google/universal-sentence-encoder/4 loaded\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import seaborn as sn\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import scipy\n",
    "from itertools import chain\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import re\n",
    "import warnings\n",
    "import math\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "module_url = \"https://tfhub.dev/google/universal-sentence-encoder/4\"\n",
    "model = hub.load(module_url)\n",
    "print (\"module %s loaded\" % module_url)\n",
    "def embed(input):\n",
    "  return model(input)\n",
    "os.chdir('/gpfs/milgram/project/chun/jk2992/rest_thoughts/') # change to your folder path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8053f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_r2z(r):\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return 0.5 * (np.log(1 + r) - np.log(1 - r))\n",
    "def conv_z2r(z):\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
    "def get_info(name):\n",
    "    tmp = name.split('_')\n",
    "    sub = tmp[0]\n",
    "    ses = tmp[1]\n",
    "    return sub, ses\n",
    "def get_num(string):\n",
    "    num = []\n",
    "    for i in range(len(string)):\n",
    "        if i % 5 == 2:\n",
    "            num.append(int(string[i]))\n",
    "    return num\n",
    "def reshape_FC(fc):\n",
    "    fc = np.transpose(fc,(2,0,1))\n",
    "    fc = np.reshape(fc,(fc.shape[0],fc.shape[1]*fc.shape[2]))\n",
    "    return fc\n",
    "def nancorr(tc1,tc2):\n",
    "    # get nan position\n",
    "    nanidx1 = np.where(np.isnan(tc1))\n",
    "    nanidx2 = np.where(np.isnan(tc2))\n",
    "    nanidx = np.union1d(nanidx1,nanidx2)\n",
    "    tc1 = np.delete(tc1,nanidx)\n",
    "    tc2 = np.delete(tc2,nanidx)\n",
    "    # run correlation\n",
    "    rval = stats.pearsonr(tc1,tc2)[0]\n",
    "    return rval\n",
    "def cosine_similarity(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    magnitude_vector1 = np.linalg.norm(vector1)\n",
    "    magnitude_vector2 = np.linalg.norm(vector2)\n",
    "    return dot_product / (magnitude_vector1 * magnitude_vector2)\n",
    "def onetail_p(real, null):\n",
    "    p = (1 + np.sum(null>=real)) / (1+len(null))\n",
    "    print(str(np.sum(null>=real))+' among '+str(len(null))+' null has higher r value than actual prediction')\n",
    "    return p\n",
    "def nanspearmanr(tc1,tc2):\n",
    "    # get nan position\n",
    "    nanidx1 = np.where(np.isnan(tc1))\n",
    "    nanidx2 = np.where(np.isnan(tc2))\n",
    "    nanidx = np.union1d(nanidx1,nanidx2)\n",
    "    tc1 = np.delete(tc1,nanidx)\n",
    "    tc2 = np.delete(tc2,nanidx)\n",
    "    # run correlation\n",
    "    rval = stats.spearmanr(tc1,tc2)[0]\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debda46e",
   "metadata": {},
   "source": [
    "# thought content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbc6265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubj = 60\n",
    "df_transcripts = pd.read_csv('./data/beh/thoughts_transcripts.csv') \n",
    "# the raw recording transcriptions will not be publicly available due to privacy concerns\n",
    "# however, we shared the embeddings of these transcripts\n",
    "sub_id = np.unique(df_transcripts['subid'])\n",
    "\n",
    "## asking if people with similar thoughts have similar FC profiles\n",
    "all_sub_embed = [] # first calculate the embeddings of overall thoughts (concatenated across trials)\n",
    "for sub in sub_id:\n",
    "    # print('Running '+str(sub))\n",
    "    thought_bysub = df_transcripts[df_transcripts['subid']==sub]['Transcriptions']\n",
    "    concate_bysub = \"\" \n",
    "    for trial in range(thought_bysub.index[0],thought_bysub.index[len(thought_bysub.index)-1]+1):\n",
    "        if pd.isna(thought_bysub[trial]):\n",
    "            pass\n",
    "        else:\n",
    "            concate_bysub = concate_bysub + '. ' + thought_bysub[trial]\n",
    "    concate_bysub = [concate_bysub]\n",
    "    this_sub_embed = embed(concate_bysub)\n",
    "    this_sub_embed = np.squeeze(this_sub_embed)\n",
    "    all_sub_embed.append(this_sub_embed)\n",
    "scipy.io.savemat('./data/beh/thought_embeddings.mat',{'embeddings':all_sub_embed})\n",
    "\n",
    "embed_sim = [] # calculate between subject similarity\n",
    "for i in range(nsubj-1):\n",
    "    for j in range(i+1,nsubj):\n",
    "        tmp_r = cosine_similarity(all_sub_embed[i],all_sub_embed[j])\n",
    "        embed_sim.append(tmp_r)\n",
    "embed_sim = np.asarray(embed_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967246f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/rwvdlsl16q96bmby7428s3700000gn/T/ipykernel_4510/783710020.py:12: RuntimeWarning: Mean of empty slice\n",
      "  this_sub = np.nanmean(fc_bysub[sub],axis=1) # calculate the mean FC profile for each individual\n"
     ]
    }
   ],
   "source": [
    "# read in brain data\n",
    "rest_fc = scipy.io.loadmat('./data/brain/rest_fc.mat')['rest'][0]\n",
    "\n",
    "# calculate FC by subject\n",
    "nsubj = len(rest_fc)\n",
    "fc_bysub = []\n",
    "for i in range(nsubj):\n",
    "    fc_bysub.append(reshape_FC(rest_fc[i]))\n",
    "\n",
    "fingerprint_bysub = []\n",
    "for sub in range(nsubj):\n",
    "    this_sub = np.nanmean(fc_bysub[sub],axis=1) # calculate the mean FC profile for each individual\n",
    "    fingerprint_bysub.append(this_sub)\n",
    "\n",
    "FP_sim = []\n",
    "for i in range(nsubj-1):\n",
    "    for j in range(i+1,nsubj):\n",
    "        tmp_r = nancorr(fingerprint_bysub[i],fingerprint_bysub[j])\n",
    "        FP_sim.append(tmp_r)\n",
    "FP_sim = np.asarray(FP_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d827c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 among 10000 null has higher r value than actual prediction\n",
      "r =  0.09619635073154363 p =  9.999000099990002e-05\n"
     ]
    }
   ],
   "source": [
    "actual_r = nanspearmanr(FP_sim,embed_sim)\n",
    "null_r = []\n",
    "niteration = 10000\n",
    "for iter in range(niteration):\n",
    "    random.shuffle(embed_sim)\n",
    "    tmp_r = nanspearmanr(FP_sim,embed_sim)\n",
    "    null_r.append(tmp_r)\n",
    "null_r = np.asarray(null_r)\n",
    "p = onetail_p(actual_r,null_r)\n",
    "print('r = ',actual_r,'p = ',p)\n",
    "\n",
    "scipy.io.savemat('./results/RSA/content_fingerprints.mat',{'actual_r':actual_r,'null_r':null_r}) # save the results for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b848910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# asking if FC dynamics also track thought fluctuations\n",
    "\n",
    "# calculate the embeddings of each trial\n",
    "embed_bysub = []\n",
    "for sub in sub_id:\n",
    "    thought_bysub = df_transcripts[df_transcripts['subid']==sub]['Transcriptions']\n",
    "    embed_sub = []\n",
    "    for trial in range(thought_bysub.index[0],thought_bysub.index[len(thought_bysub.index)-1]+1):\n",
    "        if pd.isna(thought_bysub[trial]):\n",
    "            embed_sub.append(np.full(512, np.nan))\n",
    "        else:\n",
    "            embed_sub.append(np.squeeze(embed([thought_bysub[trial]])))\n",
    "    embed_bysub.append(np.array(embed_sub))\n",
    "\n",
    "# remove sub-1044 ses1 run2 to match brain data (convertion error)\n",
    "embed_bysub[41] = np.delete(embed_bysub[41],range(8,16),axis=0)\n",
    "\n",
    "thought_sim = [] # calculate within subject between trial similarity\n",
    "for i in range(nsubj):\n",
    "    r_sub = []\n",
    "    for j in range(embed_bysub[i].shape[0]-1):\n",
    "        for k in range(j+1,embed_bysub[i].shape[0]):\n",
    "            tmp_r = cosine_similarity(embed_bysub[i][j,:],embed_bysub[i][k,:])\n",
    "            r_sub.append(tmp_r)\n",
    "    thought_sim.append(np.array(r_sub))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "55716e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate FC similarity within subject\n",
    "fc_sim = []\n",
    "for i in range(nsubj):\n",
    "    r_sub = []\n",
    "    for j in range(fc_bysub[i].shape[1]-1):\n",
    "        for k in range(j+1,fc_bysub[i].shape[1]):\n",
    "            if np.sum(np.isnan(fc_bysub[i][:,j])) == 35778 or np.sum(np.isnan(fc_bysub[i][:,k])) == 35778:\n",
    "                tmp_r = np.nan\n",
    "            else:\n",
    "                tmp_r = nancorr(fc_bysub[i][:,j],fc_bysub[i][:,k])\n",
    "            r_sub.append(tmp_r)\n",
    "    fc_sim.append(np.array(r_sub))\n",
    "\n",
    "rvals = []\n",
    "for sub in range(nsubj):\n",
    "    if np.all(np.isnan(thought_sim[sub])):\n",
    "        r_sub = np.nan\n",
    "    else:\n",
    "        r_sub = nanspearmanr(fc_sim[sub],thought_sim[sub])\n",
    "    rvals.append(r_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c068e663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 among 10000 null has higher r value than actual prediction\n",
      "r =  0.06940962247997925 p =  9.999000099990002e-05\n"
     ]
    }
   ],
   "source": [
    "actual_r = conv_z2r(np.nanmean(conv_r2z(np.array(rvals))))\n",
    "null_r = []\n",
    "niteration = 10000\n",
    "for iter in range(niteration):\n",
    "    rvals_null = []\n",
    "    for sub in range(nsubj):\n",
    "        if np.all(np.isnan(thought_sim[sub])):\n",
    "            r_sub = np.nan\n",
    "        else:\n",
    "            random.shuffle(thought_sim[sub])\n",
    "            r_sub = nanspearmanr(fc_sim[sub],thought_sim[sub])\n",
    "        rvals_null.append(r_sub)\n",
    "    null_r.append(conv_z2r(np.nanmean(conv_r2z(np.array(rvals_null)))))\n",
    "null_r = np.asarray(null_r)\n",
    "p = onetail_p(actual_r,null_r)\n",
    "print('r = ',actual_r,'p = ',p)\n",
    "\n",
    "scipy.io.savemat('./results/RSA/content_within-sub.mat',{'actual_r':actual_r,'null_r':null_r})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b8917dd",
   "metadata": {},
   "source": [
    "# thought dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e8bf807f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 60 participants\n"
     ]
    }
   ],
   "source": [
    "df_dimension = pd.read_csv('./data/beh/all_ratings.csv')\n",
    "# create a behavioral participant list\n",
    "sub_list = np.unique(df_dimension['Sub'])\n",
    "print('We have '+str(len(sub_list)) + ' participants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7d25c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_list = ['Awake','External','Future','Past','Other','Valence','Image','Word','Detail']\n",
    "all_dims = []\n",
    "for var in var_list:\n",
    "    this_dim = df_dimension[var]\n",
    "    vals = []\n",
    "    for row in range(len(this_dim)):\n",
    "        vals.append(np.array(get_num(this_dim[row])))\n",
    "    all_dims.append(np.array(vals))\n",
    "all_dims = np.array(all_dims)\n",
    "\n",
    "# make the 111th row - sub 1032 s1r1 - all nans due to response box error\n",
    "all_dims = all_dims.astype(float)\n",
    "all_dims[:,110,:] = np.nan\n",
    "\n",
    "zscored_within_dim = []\n",
    "for dim in range(len(var_list)):\n",
    "    tmp_dim = stats.zscore(all_dims[dim].flatten(), nan_policy='omit').reshape(all_dims[dim].shape)\n",
    "    zscored_within_dim.append(tmp_dim)\n",
    "zscored_within_dim = np.array(zscored_within_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37bcfa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nsubj = len(sub_list)\n",
    "avg_dimensions = []\n",
    "for sub in sub_list:\n",
    "    this_index = df_dimension[df_dimension['Sub']==sub]['Run'].index\n",
    "    tmp = zscored_within_dim[:,this_index,:]\n",
    "    tmp1 = np.mean(tmp,axis=2) #average across trials in a run\n",
    "    tmp2 = np.mean(tmp1,axis=1) #average across runs\n",
    "    avg_dimensions.append(tmp2)\n",
    "\n",
    "dimension_sim = [] # calculate between subject similarity\n",
    "for i in range(nsubj-1):\n",
    "    for j in range(i+1,nsubj):\n",
    "        if np.any(np.isnan(avg_dimensions[i])) or np.any(np.isnan(avg_dimensions[j])):\n",
    "            tmp_r = np.nan\n",
    "        else:\n",
    "            tmp_r = stats.spearmanr(avg_dimensions[i],avg_dimensions[j])[0]\n",
    "        dimension_sim.append(tmp_r)\n",
    "dimension_sim = np.asarray(dimension_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d454391c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dq/rwvdlsl16q96bmby7428s3700000gn/T/ipykernel_4510/789186149.py:11: RuntimeWarning: Mean of empty slice\n",
      "  this_sub = np.nanmean(fc_bysub[sub],axis=1) # calculate the mean FC profile for each individual\n"
     ]
    }
   ],
   "source": [
    "# read in brain data\n",
    "rest_fc = scipy.io.loadmat('./data/brain/rest_fc.mat')['rest'][0]\n",
    "# calculate FC by subject\n",
    "nsubj = len(rest_fc)\n",
    "fc_bysub = []\n",
    "for i in range(nsubj):\n",
    "    fc_bysub.append(reshape_FC(rest_fc[i]))\n",
    "\n",
    "fingerprint_bysub = []\n",
    "for sub in range(nsubj):\n",
    "    this_sub = np.nanmean(fc_bysub[sub],axis=1) # calculate the mean FC profile for each individual\n",
    "    fingerprint_bysub.append(this_sub)\n",
    "\n",
    "FP_sim = []\n",
    "for i in range(nsubj-1):\n",
    "    for j in range(i+1,nsubj):\n",
    "        tmp_r = nancorr(fingerprint_bysub[i],fingerprint_bysub[j])\n",
    "        FP_sim.append(tmp_r)\n",
    "FP_sim = np.asarray(FP_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b04aa24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026085983454496448\n",
      "1408 among 10000 null has higher r value than actual prediction\n",
      "r =  0.026085983454496448 p =  0.14088591140885912\n"
     ]
    }
   ],
   "source": [
    "actual_r = nanspearmanr(FP_sim,dimension_sim)\n",
    "print(actual_r)\n",
    "null_r = []\n",
    "niteration = 10000\n",
    "for iter in range(niteration):\n",
    "    random.shuffle(dimension_sim)\n",
    "    tmp_r = nanspearmanr(FP_sim,dimension_sim)\n",
    "    null_r.append(tmp_r)\n",
    "null_r = np.asarray(null_r)\n",
    "p = onetail_p(actual_r,null_r)\n",
    "print('r = ',actual_r,'p = ',p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05b628c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 60 participants\n",
      "All behavioral and brain data match\n"
     ]
    }
   ],
   "source": [
    "# read in brain data\n",
    "rest_fc = scipy.io.loadmat('./data/brain/rest_fc.mat')['rest'][0]\n",
    "# delete 1032 s1r1 (response box error), which is index 29 because there is no 1004 and 1019\n",
    "rest_fc[29] = np.delete(rest_fc[29],[0],axis = 0) # we don't need to do this for content or topic because that's a problem with dimension rating\n",
    "\n",
    "# calculate FC by subject\n",
    "nsubj = len(rest_fc)\n",
    "fc_bysub = []\n",
    "for i in range(nsubj):\n",
    "    fc_bysub.append(reshape_FC(rest_fc[i]))\n",
    "\n",
    "df_dimension = pd.read_csv('./data/beh/all_ratings.csv')\n",
    "# create a behavioral participant list\n",
    "sub_list = np.unique(df_dimension['Sub'])\n",
    "print('We have '+str(len(sub_list)) + ' participants')\n",
    "\n",
    "# variable list\n",
    "var_list = ['Awake','External','Future','Past','Other','Valence','Image','Word','Detail']\n",
    "\n",
    "# create a behavioral dataset by subject\n",
    "idx = -1\n",
    "beh_bysub = []\n",
    "for sub in range(len(sub_list)):\n",
    "    beh_bysub_rating = []\n",
    "    for var in range(len(var_list)):\n",
    "        sub_data = df_dimension[df_dimension['Sub']==sub_list[sub]][var_list[var]]\n",
    "        sub_vec = []\n",
    "        for run in range(len(sub_data)):\n",
    "            idx = idx + 1\n",
    "            run_data = get_num(sub_data[idx])\n",
    "            sub_vec.append(run_data)\n",
    "        sub_vec = np.asarray(sub_vec)\n",
    "        sub_vec = np.reshape(sub_vec,(sub_vec.shape[0]*sub_vec.shape[1]))\n",
    "        # zscore within subject\n",
    "        sub_vec = stats.zscore(sub_vec)\n",
    "        beh_bysub_rating.append(sub_vec)\n",
    "        if var == len(var_list) - 1:\n",
    "            pass\n",
    "        else:\n",
    "            idx = idx - len(sub_data)\n",
    "    beh_bysub_rating = np.asarray(beh_bysub_rating)\n",
    "    beh_bysub_rating = np.transpose(beh_bysub_rating)\n",
    "    beh_bysub.append(beh_bysub_rating)\n",
    "\n",
    "# remove 1032 s1r1, 1044 s1r2\n",
    "beh_bysub[29] = np.delete(beh_bysub[29],range(0,8),axis = 0)\n",
    "beh_bysub[41] = np.delete(beh_bysub[41],range(8,16),axis = 0)\n",
    "\n",
    "# let's double check the brain match behavior\n",
    "count = 0\n",
    "for i in range(nsubj):\n",
    "    # print('sub',i,len(beh_bysub[i]) == fc_bysub[i].shape[1])\n",
    "    if len(beh_bysub[i]) == fc_bysub[i].shape[1]:\n",
    "        count = count + 1\n",
    "if count == nsubj:\n",
    "    print('All behavioral and brain data match')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "04db4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "thought_sim = [] # calculate within subject between trial similarity\n",
    "for i in range(nsubj):\n",
    "    r_sub = []\n",
    "    for j in range(beh_bysub[i].shape[0]-1):\n",
    "        for k in range(j+1,beh_bysub[i].shape[0]):\n",
    "            tmp_r = stats.spearmanr(beh_bysub[i][j,:],beh_bysub[i][k,:])[0]\n",
    "            r_sub.append(tmp_r)\n",
    "    thought_sim.append(np.array(r_sub))\n",
    "\n",
    "# calculate FC similarity within subject\n",
    "fc_sim = []\n",
    "for i in range(nsubj):\n",
    "    r_sub = []\n",
    "    for j in range(fc_bysub[i].shape[1]-1):\n",
    "        for k in range(j+1,fc_bysub[i].shape[1]):\n",
    "            if np.sum(np.isnan(fc_bysub[i][:,j])) == 35778 or np.sum(np.isnan(fc_bysub[i][:,k])) == 35778:\n",
    "                tmp_r = np.nan\n",
    "            else:\n",
    "                tmp_r = nancorr(fc_bysub[i][:,j],fc_bysub[i][:,k])\n",
    "            r_sub.append(tmp_r)\n",
    "    fc_sim.append(np.array(r_sub))\n",
    "\n",
    "rvals = []\n",
    "for sub in range(nsubj):\n",
    "    if np.all(np.isnan(thought_sim[sub])):\n",
    "        r_sub = np.nan\n",
    "    else:\n",
    "        r_sub = nanspearmanr(fc_sim[sub],thought_sim[sub])\n",
    "    rvals.append(r_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a4c541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 among 10000 null has higher r value than actual prediction\n",
      "r =  0.07143891008818332 p =  9.999000099990002e-05\n"
     ]
    }
   ],
   "source": [
    "actual_r = conv_z2r(np.nanmean(conv_r2z(np.array(rvals))))\n",
    "null_r = []\n",
    "niteration = 10000\n",
    "for iter in range(niteration):\n",
    "    rvals_null = []\n",
    "    for sub in range(nsubj):\n",
    "        if np.all(np.isnan(thought_sim[sub])):\n",
    "            r_sub = np.nan\n",
    "        else:\n",
    "            random.shuffle(thought_sim[sub])\n",
    "            r_sub = nanspearmanr(fc_sim[sub],thought_sim[sub])\n",
    "        rvals_null.append(r_sub)\n",
    "    null_r.append(conv_z2r(np.nanmean(conv_r2z(np.array(rvals_null)))))\n",
    "null_r = np.asarray(null_r)\n",
    "p = onetail_p(actual_r,null_r)\n",
    "print('r = ',actual_r,'p = ',p)\n",
    "\n",
    "scipy.io.savemat('./results/RSA/dimension_within-sub.mat',{'actual_r':actual_r,'null_r':null_r})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
