{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c03f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "import scipy.io\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, linalg\n",
    "import warnings\n",
    "import math\n",
    "import random\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "def conv_r2z(r):\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return 0.5 * (np.log(1 + r) - np.log(1 - r))\n",
    "def conv_z2r(z):\n",
    "    with np.errstate(invalid='ignore', divide='ignore'):\n",
    "        return (np.exp(2 * z) - 1) / (np.exp(2 * z) + 1)\n",
    "os.chdir('/gpfs/milgram/project/chun/jk2992/rest_thoughts/') # change to your folder path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa2ed2",
   "metadata": {},
   "source": [
    "# Read in brain data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b4d605d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_FC(fc):\n",
    "    fc = np.transpose(fc,(2,0,1))\n",
    "    fc = np.reshape(fc,(fc.shape[0],fc.shape[1]*fc.shape[2]))\n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7795037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FC profiles shape: 60*(4, 8, 35778)\n"
     ]
    }
   ],
   "source": [
    "rest_FC = scipy.io.loadmat('./data/brain/rest_fc.mat')['rest'][0]\n",
    "# delete 1032 s1r1 (response box error), which is index 29 because there is no 1004 and 1019\n",
    "rest_FC[29] = np.delete(rest_FC[29],[0],axis = 0)\n",
    "print('FC profiles shape: '+str(len(rest_FC))+'*'+str(rest_FC[2].shape))\n",
    "\n",
    "# calculate FC by subject\n",
    "nsubj = len(rest_FC)\n",
    "FC_bysub = []\n",
    "for i in range(nsubj):\n",
    "    FC_bysub.append(reshape_FC(rest_FC[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888d90e",
   "metadata": {},
   "source": [
    "# Read in behavioral data (e.g., awake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963d8ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num(string):\n",
    "    num = []\n",
    "    for i in range(len(string)):\n",
    "        if i % 5 == 2:\n",
    "            num.append(int(string[i]))\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "905e75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 60 participants\n",
      "All behavioral and brain data match\n"
     ]
    }
   ],
   "source": [
    "path = './data/beh/'\n",
    "df = pd.read_csv(path + 'all_ratings.csv')\n",
    "# create a behavioral participant list\n",
    "beh_list = np.unique(df['Sub'])\n",
    "print('We have '+str(len(beh_list)) + ' participants')\n",
    "\n",
    "# create a behavioral dataset by subject\n",
    "idx = -1\n",
    "beh_bysub = []\n",
    "for sub in range(len(beh_list)):\n",
    "    sub_data = df[df['Sub']==beh_list[sub]]['Awake']\n",
    "    sub_vec = []\n",
    "    # print(str(beh_list[sub]) + ': ' + str(len(sub_data)*8))\n",
    "    for run in range(len(sub_data)):\n",
    "        idx = idx + 1\n",
    "        run_data = get_num(sub_data[idx])\n",
    "        sub_vec.append(run_data)\n",
    "    sub_vec = np.asarray(sub_vec)\n",
    "    sub_vec = np.reshape(sub_vec,(sub_vec.shape[0]*sub_vec.shape[1]))\n",
    "    # zscore the ratings\n",
    "    sub_vec = stats.zscore(sub_vec)\n",
    "    beh_bysub.append(sub_vec)\n",
    "\n",
    "# remove 1032 s1r1 (response box error), 1044 s1r2 (brain data converting error)\n",
    "beh_bysub[29] = np.delete(beh_bysub[29],range(0,8))\n",
    "beh_bysub[41] = np.delete(beh_bysub[41],range(8,16))\n",
    "\n",
    "# let's double check the brain match behavior\n",
    "count = 0\n",
    "for i in range(nsubj):\n",
    "    if len(beh_bysub[i]) == FC_bysub[i].shape[1]:\n",
    "        count = count + 1\n",
    "if count == nsubj:\n",
    "    print('All behavioral and brain data match')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50164f6f",
   "metadata": {},
   "source": [
    "# select clean data for model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07742e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 50 good participants (>20 good quality trials in brain data). They are:\n",
      " \n",
      "[1003 1005 1006 1007 1009 1011 1012 1013 1014 1016 1017 1018 1021 1022\n",
      " 1023 1024 1025 1026 1027 1028 1029 1030 1031 1032 1033 1034 1036 1037\n",
      " 1038 1039 1040 1041 1042 1043 1044 1045 1046 1047 1048 1049 1050 1051\n",
      " 1052 1055 1056 1057 1059 1060 1061 1062]\n"
     ]
    }
   ],
   "source": [
    "good_trial_bysub = []\n",
    "good_trial_id_bysub = []\n",
    "good_sub = []\n",
    "for sub in range(nsubj):\n",
    "    sub_data = FC_bysub[sub]\n",
    "    count = 0 \n",
    "    good_trial_id = []\n",
    "    for trial in range(sub_data.shape[1]):\n",
    "        # a good trial has < 1000 missing FC (3 missing nodes)\n",
    "        if np.sum(np.isnan(sub_data[:,trial])) < 1000:\n",
    "            count = count + 1\n",
    "            good_trial_id.append(trial)\n",
    "    \n",
    "    good_trial_bysub.append(count)\n",
    "    # a good participant has > 20 good trials\n",
    "    if count > 20:\n",
    "        good_sub.append(sub)\n",
    "        good_trial_id = np.transpose(good_trial_id)\n",
    "        good_trial_id_bysub.append(good_trial_id)\n",
    "\n",
    "good_sub = np.transpose(good_sub)        \n",
    "## delete sub-1040 because the rating for future and past are constant\n",
    "# good_sub = np.delete(good_sub,[30])\n",
    "# good_trial_id_bysub.pop(30)\n",
    "\n",
    "# print('we have ' + str(np.sum(good_trial_bysub)) + ' good trials in total')\n",
    "print('We have ' + str(len(good_sub)) + ' good participants (>20 good quality trials in brain data). They are:')\n",
    "print(' ')\n",
    "print(beh_list[good_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "794bdc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1531 good trials in these good participants\n",
      "All behavioral and brain data match after selecting good participants\n"
     ]
    }
   ],
   "source": [
    "# select good participants\n",
    "nsubj_good = len(good_sub)\n",
    "FC_selected, beh_selected = [], []\n",
    "for i in range(nsubj_good):\n",
    "    tmp_FC = FC_bysub[good_sub[i]]\n",
    "    tmp_FC = tmp_FC[:,good_trial_id_bysub[i]]\n",
    "    FC_selected.append(tmp_FC)\n",
    "    \n",
    "    tmp_beh = beh_bysub[good_sub[i]]\n",
    "    tmp_beh = tmp_beh[good_trial_id_bysub[i]]    \n",
    "    beh_selected.append(tmp_beh)\n",
    "\n",
    "# let's double check the brain match behavior\n",
    "count = 0\n",
    "count_trial = []\n",
    "for i in range(nsubj_good):\n",
    "    if len(beh_selected[i]) == FC_selected[i].shape[1]:\n",
    "        count = count + 1\n",
    "        count_trial.append(len(beh_selected[i]))\n",
    "if count == nsubj_good:\n",
    "    print('We have ' + str(np.sum(count_trial)) + ' good trials in these good participants')\n",
    "    print('All behavioral and brain data match after selecting good participants')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d1e47",
   "metadata": {},
   "source": [
    "# Compute correlation matrix (part of feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf561284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_r_omit_nan(tc1,tc2):\n",
    "    # get nan position\n",
    "    nanidx = np.where(np.isnan(tc1))\n",
    "\n",
    "    if len(tc1) - len(nanidx[0]) > 12:\n",
    "        # remove nan from both tc\n",
    "        tc1 = np.delete(tc1,nanidx)\n",
    "        tc2 = np.delete(tc2,nanidx)\n",
    "        # run correlation\n",
    "        rval = stats.pearsonr(tc1,tc2)[0]\n",
    "    else:\n",
    "        rval = np.nan\n",
    "    return rval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "919e971d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running sub 1/50\n",
      "Running sub 2/50\n",
      "Running sub 3/50\n",
      "Running sub 4/50\n",
      "Running sub 5/50\n",
      "Running sub 6/50\n",
      "Running sub 7/50\n",
      "Running sub 8/50\n",
      "Running sub 9/50\n",
      "Running sub 10/50\n",
      "Running sub 11/50\n",
      "Running sub 12/50\n",
      "Running sub 13/50\n",
      "Running sub 14/50\n",
      "Running sub 15/50\n",
      "Running sub 16/50\n",
      "Running sub 17/50\n",
      "Running sub 18/50\n",
      "Running sub 19/50\n",
      "Running sub 20/50\n",
      "Running sub 21/50\n",
      "Running sub 22/50\n",
      "Running sub 23/50\n",
      "Running sub 24/50\n",
      "Running sub 25/50\n",
      "Running sub 26/50\n",
      "Running sub 27/50\n",
      "Running sub 28/50\n",
      "Running sub 29/50\n",
      "Running sub 30/50\n",
      "Running sub 31/50\n",
      "Running sub 32/50\n",
      "Running sub 33/50\n",
      "Running sub 34/50\n",
      "Running sub 35/50\n",
      "Running sub 36/50\n",
      "Running sub 37/50\n",
      "Running sub 38/50\n",
      "Running sub 39/50\n",
      "Running sub 40/50\n",
      "Running sub 41/50\n",
      "Running sub 42/50\n",
      "Running sub 43/50\n",
      "Running sub 44/50\n",
      "Running sub 45/50\n",
      "Running sub 46/50\n",
      "Running sub 47/50\n",
      "Running sub 48/50\n",
      "Running sub 49/50\n",
      "Running sub 50/50\n"
     ]
    }
   ],
   "source": [
    "nR = 268\n",
    "nFC = int(nR*(nR-1)/2)\n",
    "corrmat = np.zeros((nsubj_good,nFC))\n",
    "for sub in range(nsubj_good):\n",
    "    print('Running sub ' + str(sub+1) + '/' + str(nsubj_good))\n",
    "    for feat in range(nFC):\n",
    "        corrmat[sub,feat] = get_r_omit_nan(FC_selected[sub][feat,:],beh_selected[sub])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91325184",
   "metadata": {},
   "source": [
    "# Computational modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea42f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concate(mat,ax,concate_range):\n",
    "    concate_mat = np.concatenate((mat[concate_range[0]],mat[concate_range[1]]), axis = ax)\n",
    "    for i in concate_range[2:]:\n",
    "        concate_mat = np.concatenate((concate_mat,mat[i]),axis = ax)\n",
    "    return concate_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "daffb0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def losocv(fmri,beh,nsubj,corr_mat):\n",
    "    output_acc, output_eval, output_pos_feat, output_neg_feat = [], [], np.zeros((nsubj, nR, nR)), np.zeros((nsubj, nR, nR))\n",
    "    for test_sub in range(nsubj):\n",
    "        # separate train-test subject\n",
    "        range_train = np.delete(range(nsubj),test_sub)\n",
    "        test_fmri = fmri[test_sub]\n",
    "        train_fmri = concate(fmri,1,range_train)\n",
    "        \n",
    "        test_beh = beh[test_sub]\n",
    "        train_beh = concate(beh,0,range_train)\n",
    "        \n",
    "        # features: correlation with behavior\n",
    "        train_subj_corrmat = np.delete(corr_mat,test_sub,0)\n",
    "        \n",
    "        # feature selection\n",
    "        pos_feat, neg_feat, all_feat, nanval = [], [], [], 0\n",
    "        idx = -1\n",
    "        for feat in range(int(nR*(nR-1)/2)):\n",
    "            idx=idx+1\n",
    "                \n",
    "            if np.any(np.isnan(train_subj_corrmat[:,feat])) or np.any(np.isnan(test_fmri[feat,:])) or np.any(np.isnan(train_fmri[feat,:])):\n",
    "                nanval = nanval+1\n",
    "                pass\n",
    "            else:\n",
    "                [tval,pval] = scipy.stats.ttest_1samp(train_subj_corrmat[:,feat],0)\n",
    "                if pval < thres:\n",
    "                    if np.average(train_subj_corrmat[:,feat])>0:\n",
    "                        all_feat.append(idx)\n",
    "                        pos_feat.append(idx)\n",
    "                    elif np.average(train_subj_corrmat[:,feat])<0:\n",
    "                        all_feat.append(idx)\n",
    "                        neg_feat.append(idx)\n",
    "        pos_feat, neg_feat, all_feat = np.asarray(pos_feat), np.asarray(neg_feat), np.asarray(all_feat)\n",
    "        \n",
    "        # summarize feature matrix\n",
    "        idx = -1\n",
    "        for i1 in range(nR-1):\n",
    "            for i2 in range(i1+1,nR):\n",
    "                idx = idx+1\n",
    "                if idx in pos_feat:\n",
    "                    output_pos_feat[test_sub,i1,i2]=1\n",
    "                    output_pos_feat[test_sub,i2,i1]=1\n",
    "                if idx in neg_feat:\n",
    "                    output_neg_feat[test_sub,i1,i2]=1\n",
    "                    output_neg_feat[test_sub,i2,i1]=1\n",
    "\n",
    "        train_fmri_selected = train_fmri[all_feat,:]\n",
    "        test_fmri_selected = test_fmri[all_feat,:]\n",
    "        \n",
    "        # Support vector regression with non-linear kernel\n",
    "        clf = []\n",
    "        clf = svm.SVR(kernel='rbf',max_iter=1000, gamma='auto')\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "            clf.fit(train_fmri_selected.T, train_beh)\n",
    "        predicted = clf.predict(test_fmri_selected.T)\n",
    "        output_acc.append(predicted)\n",
    "        \n",
    "        # evaluate\n",
    "        pearsonr = scipy.stats.pearsonr(test_beh, predicted)[0]\n",
    "        mse = metrics.mean_squared_error(test_beh, predicted)\n",
    "        rsq = metrics.r2_score(test_beh, predicted)\n",
    "        output_eval.append([pearsonr, mse, rsq])\n",
    "        \n",
    "        print('  subj '+str(test_sub+1)+' / '+str(nsubj)+': #feat '+str(len(all_feat))+', pearson r='+str(np.round(pearsonr,3)),', mse='+str(np.round(mse,3))+', rsq='+str(np.round(rsq,3)))\n",
    "        print('               (train) ft '+str(train_fmri_selected.shape[0])+', beh '+str(train_beh.shape[0])+\n",
    "              ', (test) ft '+str(test_fmri_selected.shape[0])+', beh '+str(test_beh.shape[0]))\n",
    "\n",
    "    return output_acc, output_eval, output_pos_feat, output_neg_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc29940b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onetail_p(real, null):\n",
    "    p = (1+np.sum(null>=real))/(1+len(null))\n",
    "    print(str(np.sum(null>=real))+' among '+str(len(null))+' null has higher value than actual prediction')\n",
    "    return p\n",
    "def onetail_p_lower(real, null):\n",
    "    p = (1+np.sum(null<=real))/(1+len(null))\n",
    "    print(str(np.sum(null<=real))+' among '+str(len(null))+' null has lower value than actual prediction')\n",
    "    return p\n",
    "niter = 10000\n",
    "def sig_test(predictions,actual,actual_r,actual_mse,actual_rsq):\n",
    "    null_dist = np.zeros((nsubj_good,niter,3)) # sig test on 3 evaluation matrices: r, mse, rsq\n",
    "    for j in range(nsubj_good):\n",
    "        for i in range(niter):\n",
    "            test_beh = actual[j]\n",
    "            random.shuffle(test_beh)\n",
    "            tmp_r = stats.pearsonr(test_beh,predictions[j])[0]\n",
    "            tmp_mse = metrics.mean_squared_error(test_beh,predictions[j])\n",
    "            tmp_rsq = metrics.r2_score(test_beh,predictions[j])\n",
    "            null_dist[j,i,0] = tmp_r\n",
    "            null_dist[j,i,1] = tmp_mse\n",
    "            null_dist[j,i,2] = tmp_rsq\n",
    "    final_output_r, final_output_mse, final_output_rsq = [], [], []\n",
    "    for k in range(niter):\n",
    "        tmp_rval = null_dist[:,k,0] # null rvals\n",
    "        tmp_rval = conv_z2r(np.mean(conv_r2z(tmp_rval)))\n",
    "        final_output_r.append(tmp_rval)\n",
    "        tmp_mse = null_dist[:,k,1] # null mse\n",
    "        tmp_mse = np.mean(tmp_mse)\n",
    "        final_output_mse.append(tmp_mse)\n",
    "        tmp_rsq = null_dist[:,k,2] # null rsq\n",
    "        tmp_rsq = np.mean(tmp_rsq)\n",
    "        final_output_rsq.append(tmp_rsq)\n",
    "    final_output_r = np.asarray(final_output_r)\n",
    "    final_output_mse = np.asarray(final_output_mse)\n",
    "    final_output_rsq = np.asarray(final_output_rsq)\n",
    "    pval_r = onetail_p(actual_r,final_output_r)\n",
    "    print('rvals: p = '+str(pval_r))\n",
    "    pval_mse = onetail_p_lower(actual_mse,final_output_mse)# because mse is the smaller the better\n",
    "    print('mse: p = '+str(pval_mse))\n",
    "    pval_rsq = onetail_p(actual_rsq,final_output_rsq)\n",
    "    print('rsq: p = '+str(pval_rsq))\n",
    "    return null_dist, pval_r, pval_mse, pval_rsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea7439f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  subj 1 / 50: #feat 1708, pearson r=0.485 , mse=0.776, rsq=0.224\n",
      "               (train) ft 1708, beh 1499, (test) ft 1708, beh 32\n",
      "  subj 2 / 50: #feat 1782, pearson r=0.139 , mse=1.058, rsq=-0.058\n",
      "               (train) ft 1782, beh 1499, (test) ft 1782, beh 32\n",
      "  subj 3 / 50: #feat 1725, pearson r=0.162 , mse=1.079, rsq=-0.023\n",
      "               (train) ft 1725, beh 1502, (test) ft 1725, beh 29\n",
      "  subj 4 / 50: #feat 1824, pearson r=-0.237 , mse=1.21, rsq=-0.21\n",
      "               (train) ft 1824, beh 1499, (test) ft 1824, beh 32\n",
      "  subj 5 / 50: #feat 1771, pearson r=0.24 , mse=1.067, rsq=-0.067\n",
      "               (train) ft 1771, beh 1499, (test) ft 1771, beh 32\n",
      "  subj 6 / 50: #feat 1746, pearson r=0.122 , mse=1.092, rsq=-0.064\n",
      "               (train) ft 1746, beh 1500, (test) ft 1746, beh 31\n",
      "  subj 7 / 50: #feat 1751, pearson r=0.185 , mse=0.996, rsq=0.004\n",
      "               (train) ft 1751, beh 1499, (test) ft 1751, beh 32\n",
      "  subj 8 / 50: #feat 1749, pearson r=0.138 , mse=1.061, rsq=-0.061\n",
      "               (train) ft 1749, beh 1499, (test) ft 1749, beh 32\n",
      "  subj 9 / 50: #feat 1741, pearson r=0.33 , mse=0.914, rsq=0.086\n",
      "               (train) ft 1741, beh 1499, (test) ft 1741, beh 32\n",
      "  subj 10 / 50: #feat 1795, pearson r=0.02 , mse=1.037, rsq=-0.037\n",
      "               (train) ft 1795, beh 1499, (test) ft 1795, beh 32\n",
      "  subj 11 / 50: #feat 1823, pearson r=-0.169 , mse=1.233, rsq=-0.233\n",
      "               (train) ft 1823, beh 1499, (test) ft 1823, beh 32\n",
      "  subj 12 / 50: #feat 1815, pearson r=-0.096 , mse=1.187, rsq=-0.219\n",
      "               (train) ft 1815, beh 1500, (test) ft 1815, beh 31\n",
      "  subj 13 / 50: #feat 1781, pearson r=-0.193 , mse=1.17, rsq=-0.17\n",
      "               (train) ft 1781, beh 1499, (test) ft 1781, beh 32\n",
      "  subj 14 / 50: #feat 1738, pearson r=0.604 , mse=0.771, rsq=0.229\n",
      "               (train) ft 1738, beh 1499, (test) ft 1738, beh 32\n",
      "  subj 15 / 50: #feat 1786, pearson r=0.331 , mse=0.894, rsq=0.106\n",
      "               (train) ft 1786, beh 1499, (test) ft 1786, beh 32\n",
      "  subj 16 / 50: #feat 1797, pearson r=-0.277 , mse=1.266, rsq=-0.308\n",
      "               (train) ft 1797, beh 1501, (test) ft 1797, beh 30\n",
      "  subj 17 / 50: #feat 1730, pearson r=0.311 , mse=1.018, rsq=0.082\n",
      "               (train) ft 1730, beh 1509, (test) ft 1730, beh 22\n",
      "  subj 18 / 50: #feat 1830, pearson r=-0.241 , mse=1.282, rsq=-0.282\n",
      "               (train) ft 1830, beh 1499, (test) ft 1830, beh 32\n",
      "  subj 19 / 50: #feat 1845, pearson r=0.189 , mse=0.994, rsq=0.006\n",
      "               (train) ft 1845, beh 1499, (test) ft 1845, beh 32\n",
      "  subj 20 / 50: #feat 1892, pearson r=-0.33 , mse=1.467, rsq=-0.467\n",
      "               (train) ft 1892, beh 1499, (test) ft 1892, beh 32\n",
      "  subj 21 / 50: #feat 1844, pearson r=-0.135 , mse=1.121, rsq=-0.179\n",
      "               (train) ft 1844, beh 1502, (test) ft 1844, beh 29\n",
      "  subj 22 / 50: #feat 1800, pearson r=-0.093 , mse=1.182, rsq=-0.182\n",
      "               (train) ft 1800, beh 1499, (test) ft 1800, beh 32\n",
      "  subj 23 / 50: #feat 1796, pearson r=0.173 , mse=0.995, rsq=0.005\n",
      "               (train) ft 1796, beh 1499, (test) ft 1796, beh 32\n",
      "  subj 24 / 50: #feat 1787, pearson r=0.014 , mse=1.243, rsq=-0.337\n",
      "               (train) ft 1787, beh 1509, (test) ft 1787, beh 22\n",
      "  subj 25 / 50: #feat 1776, pearson r=-0.015 , mse=1.14, rsq=-0.14\n",
      "               (train) ft 1776, beh 1499, (test) ft 1776, beh 32\n",
      "  subj 26 / 50: #feat 1739, pearson r=0.292 , mse=0.926, rsq=0.074\n",
      "               (train) ft 1739, beh 1499, (test) ft 1739, beh 32\n",
      "  subj 27 / 50: #feat 1748, pearson r=0.067 , mse=1.084, rsq=-0.084\n",
      "               (train) ft 1748, beh 1499, (test) ft 1748, beh 32\n",
      "  subj 28 / 50: #feat 1840, pearson r=-0.163 , mse=1.225, rsq=-0.105\n",
      "               (train) ft 1840, beh 1507, (test) ft 1840, beh 24\n",
      "  subj 29 / 50: #feat 1680, pearson r=0.508 , mse=0.712, rsq=0.251\n",
      "               (train) ft 1680, beh 1507, (test) ft 1680, beh 24\n",
      "  subj 30 / 50: #feat 1868, pearson r=-0.146 , mse=1.435, rsq=-0.239\n",
      "               (train) ft 1868, beh 1505, (test) ft 1868, beh 26\n",
      "  subj 31 / 50: #feat 1748, pearson r=0.002 , mse=1.071, rsq=-0.071\n",
      "               (train) ft 1748, beh 1499, (test) ft 1748, beh 32\n",
      "  subj 32 / 50: #feat 1787, pearson r=0.168 , mse=0.989, rsq=0.004\n",
      "               (train) ft 1787, beh 1500, (test) ft 1787, beh 31\n",
      "  subj 33 / 50: #feat 1733, pearson r=0.333 , mse=0.852, rsq=0.096\n",
      "               (train) ft 1733, beh 1500, (test) ft 1733, beh 31\n",
      "  subj 34 / 50: #feat 1782, pearson r=0.176 , mse=1.0, rsq=0.0\n",
      "               (train) ft 1782, beh 1499, (test) ft 1782, beh 32\n",
      "  subj 35 / 50: #feat 1805, pearson r=-0.137 , mse=1.29, rsq=-0.168\n",
      "               (train) ft 1805, beh 1509, (test) ft 1805, beh 22\n",
      "  subj 36 / 50: #feat 1732, pearson r=0.123 , mse=1.029, rsq=-0.029\n",
      "               (train) ft 1732, beh 1499, (test) ft 1732, beh 32\n",
      "  subj 37 / 50: #feat 1800, pearson r=-0.008 , mse=1.077, rsq=-0.077\n",
      "               (train) ft 1800, beh 1499, (test) ft 1800, beh 32\n",
      "  subj 38 / 50: #feat 1822, pearson r=-0.128 , mse=1.165, rsq=-0.165\n",
      "               (train) ft 1822, beh 1499, (test) ft 1822, beh 32\n",
      "  subj 39 / 50: #feat 1791, pearson r=-0.147 , mse=1.136, rsq=-0.235\n",
      "               (train) ft 1791, beh 1502, (test) ft 1791, beh 29\n",
      "  subj 40 / 50: #feat 1828, pearson r=-0.515 , mse=1.29, rsq=-0.29\n",
      "               (train) ft 1828, beh 1499, (test) ft 1828, beh 32\n",
      "  subj 41 / 50: #feat 1764, pearson r=0.288 , mse=0.918, rsq=0.082\n",
      "               (train) ft 1764, beh 1499, (test) ft 1764, beh 32\n",
      "  subj 42 / 50: #feat 1754, pearson r=0.34 , mse=0.887, rsq=0.113\n",
      "               (train) ft 1754, beh 1499, (test) ft 1754, beh 32\n",
      "  subj 43 / 50: #feat 1731, pearson r=0.323 , mse=0.913, rsq=0.087\n",
      "               (train) ft 1731, beh 1499, (test) ft 1731, beh 32\n",
      "  subj 44 / 50: #feat 1840, pearson r=-0.173 , mse=1.173, rsq=-0.173\n",
      "               (train) ft 1840, beh 1499, (test) ft 1840, beh 32\n",
      "  subj 45 / 50: #feat 1750, pearson r=0.154 , mse=1.048, rsq=-0.03\n",
      "               (train) ft 1750, beh 1500, (test) ft 1750, beh 31\n",
      "  subj 46 / 50: #feat 1702, pearson r=0.381 , mse=0.878, rsq=0.122\n",
      "               (train) ft 1702, beh 1499, (test) ft 1702, beh 32\n",
      "  subj 47 / 50: #feat 1788, pearson r=0.1 , mse=1.134, rsq=-0.134\n",
      "               (train) ft 1788, beh 1499, (test) ft 1788, beh 32\n",
      "  subj 48 / 50: #feat 1755, pearson r=0.092 , mse=1.051, rsq=-0.028\n",
      "               (train) ft 1755, beh 1500, (test) ft 1755, beh 31\n",
      "  subj 49 / 50: #feat 1818, pearson r=0.018 , mse=1.15, rsq=-0.15\n",
      "               (train) ft 1818, beh 1499, (test) ft 1818, beh 32\n",
      "  subj 50 / 50: #feat 1772, pearson r=0.041 , mse=1.124, rsq=-0.124\n",
      "               (train) ft 1772, beh 1499, (test) ft 1772, beh 32\n"
     ]
    }
   ],
   "source": [
    "thres = 0.05\n",
    "output_acc, output_eval, output_pos_feat, output_neg_feat = losocv(FC_selected,beh_selected,nsubj_good,corrmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5e667a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean = 0.07738535921359382, STD = 0.2329840465404623\n",
      "22 among 10000 null has higher value than actual prediction\n",
      "rvals: p = 0.0022997700229977\n",
      "15 among 10000 null has lower value than actual prediction\n",
      "mse: p = 0.0015998400159984002\n",
      "15 among 10000 null has higher value than actual prediction\n",
      "rsq: p = 0.0015998400159984002\n"
     ]
    }
   ],
   "source": [
    "# significance testing with permutation (shuffling behavior for 10000 times)\n",
    "output_eval = np.asarray(output_eval)\n",
    "# fig, ax = plt.subplots(dpi = 800)\n",
    "# ax.hist(output_eval[:,0], color='gray')\n",
    "# ax.spines[['right', 'top']].set_visible(False)\n",
    "# plt.axvline(conv_z2r(np.mean(conv_r2z(output_eval[:,0]))),color = 'black')\n",
    "print('Mean = ' + str(conv_z2r(np.mean(conv_r2z(output_eval[:,0])))) + ', STD = '+ str(np.std(output_eval[:,0])))\n",
    "null_dist, p1, p2, p3 = sig_test(output_acc,beh_selected,conv_z2r(np.mean(conv_r2z(output_eval[:,0]))),np.mean(output_eval[:,1]),np.mean(output_eval[:,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e367022",
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath = './results/CPMs/'\n",
    "if not os.path.exists(savepath):\n",
    "    os.makedirs(savepath)\n",
    "# results = {'acc':output_acc, 'eval':output_eval,'p_r':p1, 'p_mse':p2, 'p_rsq': p3}\n",
    "# scipy.io.savemat(savepath+'a_awake.mat',results)\n",
    "\n",
    "# # save the null to plot the fancy figure using step05_plot_SVR.R\n",
    "# results = {'acc':output_acc, 'eval':output_eval,'p_r':p1, 'p_mse':p2, 'p_rsq': p3, 'null':null_dist}\n",
    "# scipy.io.savemat(savepath+'a_awake_null.mat',results)\n",
    "\n",
    "# # save the selected features in each round of cross-validation to replicate the FC networks or for out-of-sample prediction\n",
    "# not saving these results for now due to file size limit on github (for sharing). Please run this for your own analysis\n",
    "results = {'acc':output_acc, 'eval':output_eval,'p_r':p1, 'p_mse':p2, 'pos_feat':output_pos_feat, 'neg_feat':output_neg_feat}\n",
    "scipy.io.savemat(savepath+'a_awake_features.mat',results)\n",
    "\n",
    "## repeat the same procedure for every thought dimension."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e34d8",
   "metadata": {},
   "source": [
    "# Correct for multiple comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "381e8dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pvals for r: [0.0207, 0.0027, 0.0009, 1.0, 0.441, 0.0018, 0.0027, 1.0, 1.0]\n",
      " \n",
      "pvals for mse: [0.0144, 0.0009, 0.0009, 1.0, 0.3276, 0.0018, 0.0054, 1.0, 1.0]\n",
      " \n",
      "pvals for rsq: [0.0144, 0.0009, 0.0009, 1.0, 0.3699, 0.0009, 0.0045, 1.0, 1.0]\n",
      " \n"
     ]
    }
   ],
   "source": [
    "## run this after you finished running all 9 dimensions\n",
    "savepath = './results/CPMs/'\n",
    "vars = ['a_awake','b_external','c_future','d_past','e_other','f_valence','g_image','h_word','i_detail']\n",
    "p_values = []\n",
    "for var in vars:\n",
    "    results = scipy.io.loadmat(savepath + var + '.mat')\n",
    "    p_r, p_mse, p_rsq = results['p_r'][0][0], results['p_mse'][0][0], results['p_rsq'][0][0]\n",
    "    p_values.append(np.array([p_r, p_mse, p_rsq]))\n",
    "p_values = np.array(p_values)\n",
    "\n",
    "# let's use a strict method for correcting multiple comparison\n",
    "decision, adj_pvals, sidak_aplha, bonf_alpha  = multipletests(p_values[:,0],alpha = .01, method = 'bonferroni')\n",
    "corrected_pvals = [round(i,4) for i in adj_pvals]\n",
    "print('pvals for r:',corrected_pvals)\n",
    "print(' ')\n",
    "\n",
    "decision, adj_pvals, sidak_aplha, bonf_alpha  = multipletests(p_values[:,1],alpha = .01, method = 'bonferroni')\n",
    "corrected_pvals = [round(i,4) for i in adj_pvals]\n",
    "print('pvals for mse:',corrected_pvals)\n",
    "print(' ')\n",
    "\n",
    "decision, adj_pvals, sidak_aplha, bonf_alpha  = multipletests(p_values[:,2],alpha = .01, method = 'bonferroni')\n",
    "corrected_pvals = [round(i,4) for i in adj_pvals]\n",
    "print('pvals for rsq:',corrected_pvals)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbbc74b",
   "metadata": {},
   "source": [
    "# Create a clean result file to plot a beautiful figure in R (step04_plot_SVR.R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55e3f323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_null(null,measure): # measure: 0=rvals, 1=mse, 2=rsq\n",
    "    new_null = []\n",
    "    for iter in range(niter):\n",
    "        this_iter = null[:,iter,measure]\n",
    "        if measure == 0:\n",
    "            avg = conv_z2r(np.mean(conv_r2z(this_iter)))\n",
    "        else:\n",
    "            avg = np.mean(this_iter)\n",
    "        new_null.append(avg)\n",
    "    return np.array(new_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5dc072dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "measures = ['r','mse','rsq']\n",
    "for mi, measure in enumerate(measures):\n",
    "    actual_vals, actual_labels = np.array([]), np.array([])\n",
    "    null_vals, null_labels = np.array([]), np.array([])\n",
    "    for var in vars:\n",
    "        results = scipy.io.loadmat(savepath + var + '_null.mat')\n",
    "        ## load the actual values\n",
    "        vals = results['eval'][:,0]\n",
    "        label_vec = [var]*len(vals) # create the labels\n",
    "        actual_vals = np.concatenate((actual_vals,vals))\n",
    "        actual_labels = np.concatenate((actual_labels,label_vec))\n",
    "        ## load the null\n",
    "        null = average_null(results['null'],0)\n",
    "        null_vals = np.concatenate((null_vals,null))\n",
    "        label_vec = [var]*niter # create the labels\n",
    "        null_labels = np.concatenate((null_labels,label_vec))\n",
    "\n",
    "    # saving the actual results\n",
    "    df_actual = pd.DataFrame({\n",
    "        'Group':np.array(actual_labels).flatten(),\n",
    "        'vals':np.array(actual_vals).flatten()})\n",
    "    # saving the null\n",
    "    df_null = pd.DataFrame({\n",
    "        'Group':np.array(null_labels).flatten(),\n",
    "        'vals':np.array(null_vals).flatten()})\n",
    "\n",
    "    df_actual.to_csv(savepath+measure+'_actual.csv',index=False)\n",
    "    df_null.to_csv(savepath+measure+'_null.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
